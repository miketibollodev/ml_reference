{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cross-Validation\n",
    "**Cross-Validation**: a technique used to evaluate the generalization performance of a model (important: the purpose is not to train a model).\n",
    "\n",
    "This is done by taking the training set, splitting it into some smaller sets for a number of iterations, where a new model is fit each time. The model for each iteration will be evaluated using this internally-created validation set.\n",
    "\n",
    "Cross-validation avoids *overfitting* by using the classic approach of a training/validation split approach before testing on the test set. It also avoids *underfitting* - which occurs by having less samples to train on when splitting the training set into smaller training and validation sets - by using multiple iterations of different sets from a single dataset.\n",
    "\n",
    "**There should always be a separate, final test set that is used for final evaluation.**"
   ],
   "id": "bf062258fe1bb60d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cross-Validation Strategies",
   "id": "7fb71343ce07d47a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`KFold`: divides all samples in the dataset into `k` groups of samples (called folds), of equal sizes (if possible). Then, each iteration will train on `k-1` folds and test on `1` fold. Thus, there will be `k` iterations. *This assumes that data is independently and identically distributed.*\n",
    "\n",
    "Here is an example of a `KFold(n_splits=3, shuffle=True)`\n",
    "\n",
    "```\n",
    "Data: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11\n",
    "\n",
    "Fold 1: 7, 2, 9, 1\n",
    "Fold 2: 10, 3, 6, 4\n",
    "Fold 3: 0, 11, 5, 8\n",
    "\n",
    "- Split 1 -\n",
    "Train: 10, 3, 6, 4, 0, 11, 5, 8\n",
    "Test: 7, 2, 9, 1\n",
    "\n",
    "- Split 2 -\n",
    "Train: 7, 2, 9, 1, 0, 11, 5, 8\n",
    "Test: 10, 3, 6, 4\n",
    "\n",
    "- Split 3 -\n",
    "Train: 10, 3, 6, 4, 7, 2, 9, 1\n",
    "Test: 0, 11, 5, 8\n",
    "```\n",
    "\n",
    "`RepeatedKFold` repeats `KFold` for `n` times, producing different splits in each repetition.\n",
    "\n",
    "`StratifiedKFold` returns stratified folds, meaning each set contains approximately the same percentage of samples of each target class as the complete set. When data is split into folds, there could be models that are exposed to more or less of a certain target class."
   ],
   "id": "334268a652c158f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`ShuffleSplit`: divides the data into user-defined number of independent train and test dataset splits. Samples are first shuffled, then split. Unlike `KFold`, splits could overlap.",
   "id": "1fd17e21f85b99d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cross-Validation Methods",
   "id": "dcc5989d3a617258"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`cross_val_score` returns the `score` method of the estimator for each fold of the cross-validation. This can be changed using the `scoring` parameter.",
   "id": "58af09bfafb1e7f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "data, target = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\n",
    "scores = cross_val_score(\n",
    "    LogisticRegression(),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "print(f\"Scores: {scores}\")"
   ],
   "id": "fa713e835f188b3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`cross_validate` enables the use of multiple evaluation metrics, and contains detailed information like fit times, score times, and the test score.",
   "id": "9fcf46529295bef6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "data, target = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\n",
    "cv_results = cross_validate(\n",
    "    LogisticRegression(),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "print(f\"Fit times: {cv_results[\"fit_time\"]}\")\n",
    "print(f\"Score times: {cv_results[\"score_time\"]}\")\n",
    "print(f\"Test scores: {cv_results[\"test_score\"]}\")"
   ],
   "id": "cfbb04298821ffae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
